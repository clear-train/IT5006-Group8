





import pandas as pd
import geopandas as gpd
import matplotlib.pyplot as plt
import seaborn as sns
from shapely import wkt
import textwrap

sns.set_style("whitegrid")
plt.rcParams["figure.figsize"] = (12, 6)






CRIME_PATH = '/Users/liqinkai/Programs/it5006/IT5006-Group8/Crimes_-_2001_to_Present_20260203.csv'

crime_usecols = [
    'Date',
    'Primary Type',
    'Description',
    'Community Area',
    'Location Description',
    'Domestic',
    'Arrest'
]

chunks = []
chunksize = 500_000

for chunk in pd.read_csv(CRIME_PATH, usecols=crime_usecols, chunksize=chunksize):
    # Convert Date to datetime using known format; invalid parse -> NaT
    chunk['Date'] = pd.to_datetime(
        chunk['Date'],
        format='%m/%d/%Y %I:%M:%S %p',
        errors='coerce'
    )

    # Filter to 2015–2024 inclusive (drop out-of-scope years early)
    mask = (chunk['Date'].dt.year >= 2015) & (chunk['Date'].dt.year <= 2024)
    chunk = chunk.loc[mask].copy()

    # Drop rows missing Date or Community Area after filtering
    chunk = chunk.dropna(subset=['Date', 'Community Area'])

    chunks.append(chunk)

crime_df = pd.concat(chunks, ignore_index=True)

print(f'Loaded rows: {len(crime_df):,}')
print(crime_df.head())






BOUNDARY_PATH = 'Boundaries_-_Community_Areas_20260205.csv'

geo_df = pd.read_csv(BOUNDARY_PATH, usecols=['the_geom', 'AREA_NUMBE', 'COMMUNITY'])

# Convert WKT -> geometry, guarding against missing geometry
geo_df = geo_df.dropna(subset=['the_geom']).copy()
geo_df['geometry'] = geo_df['the_geom'].apply(wkt.loads)
geo_df = gpd.GeoDataFrame(geo_df, geometry='geometry', crs='EPSG:4326')

# Ensure AREA_NUMBE is int
geo_df['AREA_NUMBE'] = geo_df['AREA_NUMBE'].astype(int)

geo_df.head()






# Build mapping: AREA_NUMBE -> COMMUNITY
area_to_name = dict(zip(geo_df['AREA_NUMBE'], geo_df['COMMUNITY']))

# Ensure community area is integer (safe after dropping NaN)
crime_df['Community Area'] = crime_df['Community Area'].astype(int)
crime_df['Community_Name'] = crime_df['Community Area'].map(area_to_name)

# Convert text columns to category for memory efficiency
crime_df['Primary Type'] = crime_df['Primary Type'].astype('category')
crime_df['Description'] = crime_df['Description'].astype('category')
crime_df['Location Description'] = crime_df['Location Description'].astype('category')

crime_df.head()






crime_df['Year'] = crime_df['Date'].dt.year
crime_df['Month'] = crime_df['Date'].dt.month
crime_df['Day_of_Week'] = crime_df['Date'].dt.day_name()
crime_df['Hour'] = crime_df['Date'].dt.hour

crime_df.info(memory_usage='deep')









monthly_counts = crime_df.groupby('Month').size()

plt.figure()
sns.lineplot(x=monthly_counts.index, y=monthly_counts.values, marker='o')
plt.title('Monthly Crime Trend (2015–2024)')
plt.xlabel('Month')
plt.ylabel('Number of Crimes')
plt.tight_layout()
plt.show()






day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']

heatmap_data = (
    crime_df.groupby(['Day_of_Week', 'Hour'])
    .size()
    .unstack(fill_value=0)
    .reindex(day_order)
)

plt.figure(figsize=(14, 6))
sns.heatmap(heatmap_data, cmap='Reds')
plt.title('Crime Frequency Heatmap: Day of Week vs Hour')
plt.xlabel('Hour of Day')
plt.ylabel('Day of Week')
plt.tight_layout()
plt.show()









community_counts = crime_df.groupby('Community Area').size().reset_index(name='Crime_Count')

geo_merged = geo_df.merge(community_counts, left_on='AREA_NUMBE', right_on='Community Area', how='left')
geo_merged['Crime_Count'] = geo_merged['Crime_Count'].fillna(0)

fig, ax = plt.subplots(1, 1, figsize=(10, 10))
geo_merged.plot(column='Crime_Count', cmap='OrRd', linewidth=0.4, ax=ax, edgecolor='white', legend=True)
ax.set_title('Crime Density by Community Area (2015-2024)')
ax.axis('off')
plt.tight_layout()
plt.show()






top_locations = crime_df['Location Description'].value_counts().head(10)

# Wrap long labels to improve readability
wrapped_labels = [
    textwrap.fill(str(label), width=22) for label in top_locations.index
]

plt.figure(figsize=(10, 6))
ax = sns.barplot(
    x=top_locations.values,
    y=wrapped_labels,
    color='steelblue',
    edgecolor='black',
    linewidth=1.0
)
ax.set_title('Top 10 Crime Location Descriptions (2015–2024)')
ax.set_xlabel('Number of Crimes')
ax.set_ylabel('Location Description')
plt.tight_layout()
plt.show()









top_communities = crime_df['Community_Name'].value_counts().head(10)

plt.figure()
sns.barplot(x=top_communities.values, y=top_communities.index, color='teal')
plt.title('Top 10 Communities by Crime Count (2015–2024)')
plt.xlabel('Number of Crimes')
plt.ylabel('Community')
plt.tight_layout()
plt.show()






domestic_counts = crime_df['Domestic'].value_counts()

values = [domestic_counts.get(False, 0), domestic_counts.get(True, 0)]

plt.figure(figsize=(6, 6))
plt.pie(values, labels=['Non-Domestic', 'Domestic'], autopct='%1.1f%%', startangle=90)
plt.title('Domestic vs Non-Domestic Crimes (2015–2024)')
plt.tight_layout()
plt.show()









import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('C:\\Users\\LENOVO\\Downloads\\Crimes_-_2026_20260209.csv')

top_crime_types = df['Primary Type'].value_counts().nlargest(8).index
df_filtered = df[df['Primary Type'].isin(top_crime_types)]


district_crime_counts = pd.crosstab(df_filtered['District'], df_filtered['Primary Type'])

district_crime_pct = district_crime_counts.div(district_crime_counts.sum(axis=1), axis=0)


district_crime_pct = district_crime_pct.sort_values(by='THEFT', ascending=False)
plt.figure(figsize=(15, 8))
district_crime_pct.plot(kind='bar', stacked=True, figsize=(15, 8), colormap='tab10', edgecolor='white')

plt.title('Crime Specialization Profile by District (2026)', fontsize=16, fontweight='bold')
plt.ylabel('Proportion of Crimes within District', fontsize=12)
plt.xlabel('Police District', fontsize=12)
plt.legend(title='Crime Type', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.savefig('district_specialization_stacked_bar.png')
plt.show()


## Plot 2: Z-Score Anomaly Identification

The Z-Score measures the extent to which a particular crime ratio in a police district deviates from the city average.


district_zscore = district_crime_pct.apply(zscore)

plt.figure(figsize=(12, 10))
sns.heatmap(district_zscore, 
            annot=True,       
            fmt=".1f",        
            cmap='RdBu_r',    
            center=0,         
            linewidths=.5)

plt.title('Crime Specialization Heatmap (Z-Scores of Proportions)', fontsize=16, fontweight='bold')
plt.ylabel('Police District', fontsize=12)
plt.xlabel('Crime Type', fontsize=12)
plt.tight_layout()
plt.savefig('district_specialization_heatmap_zscore.png')
plt.show()

print("--- report---")
print("\nTop 3 districts with the highest proportion of theft (THEFT).:")
print(district_crime_pct['THEFT'].head(3))

print("\nThe top 3 districts with the highest proportion of violent assault (BATTERY).:")
print(district_crime_pct['BATTERY'].sort_values(ascending=False).head(3))


# Section E: Enforcement & Outcome Correlation


## Plot 1: SArrest Rate by Location Type

Calculate the average arrest rate for the top 15 high-frequency crime locations.


import matplotlib.pyplot as plt
import seaborn as sns
# 1. 计算不同地点的逮捕率
top_locations = df['Location Description'].value_counts().nlargest(15).index
location_arrest = df[df['Location Description'].isin(top_locations)].groupby('Location Description')['Arrest'].mean().sort_values(ascending=False)

# 2. 绘制案发地点逮捕率排行图
plt.figure(figsize=(10, 8))
sns.barplot(x=location_arrest.values, y=location_arrest.index, palette='magma')
plt.title('Arrest Rate by Location Description (2026)')
plt.xlabel('Arrest Probability')
plt.savefig('location_arrest_rate.png')


## Plot 2: Crime-Location Arrest Heatmap
Cross-arrest heat map of location and crime type








OUTPUT_PATH = 'chicago_crime_2015_2024_enriched.parquet'
crime_df.to_parquet(OUTPUT_PATH, index=False)
print(f'Saved enriched data to {OUTPUT_PATH}')

